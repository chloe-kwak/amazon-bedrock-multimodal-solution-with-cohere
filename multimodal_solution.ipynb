{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Cohere Embed v4 + OpenSearch Serverless ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ì†”ë£¨ì…˜\n",
    "\n",
    "## ğŸ“‹ ê°œìš”\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **Amazon Bedrockì˜ Cohere Embed v4**ì™€ **OpenSearch Serverless**ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ê²°í•©í•œ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥\n",
    "- **ë©€í‹°ëª¨ë‹¬ ì„ë² ë”©**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ 1536ì°¨ì› ë²¡í„°ë¡œ í†µí•©\n",
    "- **ì‹¤ì‹œê°„ ë²¡í„° ê²€ìƒ‰**: HNSW ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ê³ ì„±ëŠ¥ ê²€ìƒ‰\n",
    "- **ìœ ì—°í•œ ê²€ìƒ‰ ëª¨ë“œ**: í…ìŠ¤íŠ¸ ì „ìš©, ì´ë¯¸ì§€ ì „ìš©, ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì§€ì›\n",
    "- **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: OpenSearch Serverlessë¡œ ìë™ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "## ğŸ—ï¸ ì•„í‚¤í…ì²˜\n",
    "```\n",
    "í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ â†’ Cohere Embed v4 â†’ 1536D ë²¡í„° â†’ OpenSearch (HNSW) â†’ ê²€ìƒ‰ ê²°ê³¼\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  AWS í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” êµ¬ì„± ìš”ì†Œ:\n",
    "- **boto3**: AWS SDK\n",
    "- **opensearch-py**: OpenSearch í´ë¼ì´ì–¸íŠ¸\n",
    "- **Pillow**: ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "- **requests-aws4auth**: AWS ì¸ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "!pip install boto3>=1.34.0 opensearch-py>=2.4.0 requests-aws4auth>=1.2.3 pandas>=2.0.0 Pillow>=10.0.0 python-dotenv>=1.0.0\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ì„¤ì •\n",
    "REGION = 'us-east-1'\n",
    "INDEX_NAME = 'fashion-items-1'\n",
    "\n",
    "# AWS í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=REGION)\n",
    "opensearch_client = boto3.client('opensearchserverless', region_name=REGION)\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, REGION, 'aoss', session_token=credentials.token)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 2. OpenSearch Serverless ì»¬ë ‰ì…˜ ì„¤ì •\n",
    "\n",
    "ê¸°ì¡´ OpenSearch ì»¬ë ‰ì…˜ì„ ì°¾ê±°ë‚˜ .env íŒŒì¼ì—ì„œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì„¤ì • ë°©ë²•:\n",
    "1. **ìë™ ê²€ìƒ‰**: í™œì„± ìƒíƒœì˜ OpenSearch ì»¬ë ‰ì…˜ ìë™ íƒì§€\n",
    "2. **ìˆ˜ë™ ì„¤ì •**: `.env` íŒŒì¼ì— `OPENSEARCH_ENDPOINT` ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envì—ì„œ ì—”ë“œí¬ì¸íŠ¸ ì½ê¸°\n",
    "EXISTING_ENDPOINT = os.getenv('OPENSEARCH_ENDPOINT')\n",
    "\n",
    "def get_or_create_collection():\n",
    "    if EXISTING_ENDPOINT:\n",
    "        print(f\"âœ… .envì—ì„œ ì—”ë“œí¬ì¸íŠ¸ ë¡œë“œ: {EXISTING_ENDPOINT[:30]}...\")\n",
    "        return EXISTING_ENDPOINT\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ” í™œì„± OpenSearch ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì¤‘...\")\n",
    "        collections = opensearch_client.list_collections()\n",
    "        for collection in collections[\"collectionSummaries\"]:\n",
    "            if collection[\"status\"] == \"ACTIVE\":\n",
    "                endpoint = f\"https://{collection[\"id\"]}.{REGION}.aoss.amazonaws.com\"\n",
    "                print(f\"âœ… í™œì„± ì»¬ë ‰ì…˜ ë°œê²¬: {collection[\"name\"]} -> {endpoint[:30]}...\")\n",
    "                return endpoint\n",
    "        \n",
    "        print(\"âŒ í™œì„± ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ .env íŒŒì¼ì— OPENSEARCH_ENDPOINTë¥¼ ì„¤ì •í•˜ê±°ë‚˜ OpenSearch ì»¬ë ‰ì…˜ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ’¡ .env íŒŒì¼ì— OPENSEARCH_ENDPOINTë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "\n",
    "ENDPOINT = get_or_create_collection()\n",
    "if not ENDPOINT:\n",
    "    raise Exception(\"OpenSearch ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ ì»¬ë ‰ì…˜ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "print(f\"ğŸ¯ ì‚¬ìš©í•  ì—”ë“œí¬ì¸íŠ¸: {ENDPOINT[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 3. ë°ì´í„° ì•¡ì„¸ìŠ¤ ê¶Œí•œ ì„¤ì •\n",
    "\n",
    "OpenSearch Serverlessì— ëŒ€í•œ ë°ì´í„° ì•¡ì„¸ìŠ¤ ì •ì±…ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê¶Œí•œ ë²”ìœ„:\n",
    "- **ì¸ë±ìŠ¤ ê¶Œí•œ**: ìƒì„±, ì‚­ì œ, ì—…ë°ì´íŠ¸, ì½ê¸°, ì“°ê¸°\n",
    "- **ì»¬ë ‰ì…˜ ê¶Œí•œ**: ì»¬ë ‰ì…˜ ì•„ì´í…œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì•¡ì„¸ìŠ¤ ê¶Œí•œ ì„¤ì •\n",
    "def setup_data_access_policy():\n",
    "    try:\n",
    "        # í˜„ì¬ ì‚¬ìš©ì ARN ê°€ì ¸ì˜¤ê¸°\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        user_arn = identity['Arn']\n",
    "        \n",
    "        # ë°ì´í„° ì•¡ì„¸ìŠ¤ ì •ì±…\n",
    "        policy = [\n",
    "            {\n",
    "                \"Rules\": [\n",
    "                    {\n",
    "                        \"ResourceType\": \"index\",\n",
    "                        \"Resource\": [\"index/*/*\"],\n",
    "                        \"Permission\": [\n",
    "                            \"aoss:CreateIndex\", \"aoss:DeleteIndex\", \"aoss:UpdateIndex\",\n",
    "                            \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\"\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"ResourceType\": \"collection\",\n",
    "                        \"Resource\": [\"collection/*\"],\n",
    "                        \"Permission\": [\"aoss:CreateCollectionItems\"]\n",
    "                    }\n",
    "                ],\n",
    "                \"Principal\": [user_arn]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        opensearch_client.create_access_policy(\n",
    "            name='multimodal-data-access-policy',\n",
    "            type='data',\n",
    "            policy=json.dumps(policy)\n",
    "        )\n",
    "        print(f\"âœ… ë°ì´í„° ì•¡ì„¸ìŠ¤ ì •ì±… ìƒì„± ì™„ë£Œ: {user_arn}\")\n",
    "    except Exception as e:\n",
    "        if 'ConflictException' in str(e):\n",
    "            print(\"â„¹ï¸ ë°ì´í„° ì•¡ì„¸ìŠ¤ ì •ì±…ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì •ì±… ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "setup_data_access_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 4. HNSW ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±\n",
    "\n",
    "ê³ ì„±ëŠ¥ ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ HNSW (Hierarchical Navigable Small World) ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì¸ë±ìŠ¤ ì„¤ì •:\n",
    "- **ì°¨ì›**: 1536 (Cohere Embed v4)\n",
    "- **ì•Œê³ ë¦¬ì¦˜**: HNSW\n",
    "- **ìœ ì‚¬ë„**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "- **ì—”ì§„**: nmslib (ê³ ì„±ëŠ¥)\n",
    "\n",
    "### HNSW ì¥ì :\n",
    "- âš¡ **ë¹ ë¥¸ ê²€ìƒ‰**: O(log N) ì‹œê°„ ë³µì¡ë„\n",
    "- ğŸ“ˆ **í™•ì¥ì„±**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬\n",
    "- ğŸ¯ **ì •í™•ì„±**: ë†’ì€ ê²€ìƒ‰ í’ˆì§ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# OpenSearch í´ë¼ì´ì–¸íŠ¸ ë° ì¸ë±ìŠ¤ ìƒì„±\nclient = OpenSearch(\n    hosts=[{'host': ENDPOINT.replace('https://', ''), 'port': 443}],\n    http_auth=awsauth,\n    use_ssl=True,\n    verify_certs=True,\n    connection_class=RequestsHttpConnection,\n    timeout=300,  # ì „ì—­ íƒ€ì„ì•„ì›ƒ 5ë¶„\n    max_retries=3,\n    retry_on_timeout=True\n)\n\n# 1536 ì°¨ì› ì¸ë±ìŠ¤ ë§¤í•‘\nmapping = {\n    \"settings\": {\"index\": {\"knn\": True}},\n    \"mappings\": {\n        \"properties\": {\n            \"item_id\": {\"type\": \"keyword\"},\n            \"title\": {\"type\": \"text\"},\n            \"description\": {\"type\": \"text\"},\n            \"category\": {\"type\": \"keyword\"},\n            \"brand\": {\"type\": \"keyword\"},\n            \"price\": {\"type\": \"float\"},\n            \"color\": {\"type\": \"keyword\"},\n            \"multimodal_embedding\": {\n                \"type\": \"knn_vector\",\n                \"dimension\": 1536,\n                \"method\": {\"name\": \"hnsw\", \"space_type\": \"cosinesimil\", \"engine\": \"nmslib\"}\n            }\n        }\n    }\n}\n\nif client.indices.exists(index=INDEX_NAME, request_timeout=300):\n    client.indices.delete(index=INDEX_NAME, request_timeout=300)\nclient.indices.create(index=INDEX_NAME, body=mapping, request_timeout=300)\nprint(\"1536 ì°¨ì› ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 5. ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ìš© íŒ¨ì…˜ ì•„ì´í…œ ë°ì´í„°ì™€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë°ì´í„° êµ¬ì¡°:\n",
    "- **ë©”íƒ€ë°ì´í„°**: ì œëª©, ì„¤ëª…, ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ, ê°€ê²©, ìƒ‰ìƒ\n",
    "- **ì´ë¯¸ì§€**: ìƒ‰ìƒë³„ 400x400 ìƒ˜í”Œ ì´ë¯¸ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "os.makedirs('data/images', exist_ok=True)\n",
    "\n",
    "sample_items = [\n",
    "    {'item_id': 'item_001', 'title': 'ë¸”ë£¨ ë°ë‹˜ ì¬í‚·', 'description': 'ìºì£¼ì–¼í•œ ìŠ¤íƒ€ì¼ì˜ í´ë˜ì‹ ë¸”ë£¨ ë°ë‹˜ ì¬í‚·', 'category': 'ì•„ìš°í„°', 'brand': 'ìŠ¤íƒ€ì¼ì½”', 'price': 89.99, 'color': 'ë¸”ë£¨'},\n",
    "    {'item_id': 'item_002', 'title': 'ë¸”ë™ ì´ë¸Œë‹ ë“œë ˆìŠ¤', 'description': 'ìš°ì•„í•œ ë¸”ë™ ë“œë ˆìŠ¤ë¡œ íŠ¹ë³„í•œ í–‰ì‚¬ì— ì í•©', 'category': 'ë“œë ˆìŠ¤', 'brand': 'ì—˜ë ˆê°„ìŠ¤', 'price': 159.99, 'color': 'ë¸”ë™'},\n",
    "    {'item_id': 'item_003', 'title': 'í™”ì´íŠ¸ ìŠ¤ë‹ˆì»¤ì¦ˆ', 'description': 'í¸ì•ˆí•˜ê³  ìŠ¤íƒ€ì¼ë¦¬ì‹œí•œ í™”ì´íŠ¸ ìš´ë™í™”', 'category': 'ì‹ ë°œ', 'brand': 'ì»´í¬íŠ¸ìŠ¤í…', 'price': 79.99, 'color': 'í™”ì´íŠ¸'},\n",
    "    {'item_id': 'item_004', 'title': 'ë ˆë“œ ìš¸ ìŠ¤ì›¨í„°', 'description': 'ë”°ëœ»í•œ ê²¨ìš¸ìš© ë¹¨ê°„ ìš¸ ìŠ¤ì›¨í„°', 'category': 'ìƒì˜', 'brand': 'ì›œì›¨ì–´', 'price': 69.99, 'color': 'ë ˆë“œ'},\n",
    "    {'item_id': 'item_005', 'title': 'ë¸Œë¼ìš´ ê°€ì£½ í•¸ë“œë°±', 'description': 'í”„ë¦¬ë¯¸ì—„ ë¸Œë¼ìš´ ê°€ì£½ í•¸ë“œë°±', 'category': 'ì•¡ì„¸ì„œë¦¬', 'brand': 'ë ˆë”í¬ë˜í”„íŠ¸', 'price': 129.99, 'color': 'ë¸Œë¼ìš´'}\n",
    "]\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±\n",
    "colors = {'ë¸”ë£¨': (70, 130, 180), 'ë¸”ë™': (0, 0, 0), 'í™”ì´íŠ¸': (255, 255, 255), 'ë ˆë“œ': (220, 20, 60), 'ë¸Œë¼ìš´': (139, 69, 19)}\n",
    "for item in sample_items:\n",
    "    color = colors[item['color']]\n",
    "    img = Image.new('RGB', (400, 400), color)\n",
    "    img.save(f\"data/images/{item['item_id']}.jpg\")\n",
    "\n",
    "print(f\"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(sample_items)}ê°œ ì•„ì´í…œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  6. ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "Cohere Embed v4ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ê²°í•©í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì§€ì› ëª¨ë“œ:\n",
    "- **í…ìŠ¤íŠ¸ ì „ìš©**: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì„ë² ë”© ìƒì„±\n",
    "- **ë©€í‹°ëª¨ë‹¬**: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ê²°í•© ì„ë² ë”©\n",
    "\n",
    "### ì„ë² ë”© íŠ¹ì§•:\n",
    "- **ì°¨ì›**: 1536\n",
    "- **íƒ€ì…**: float\n",
    "- **ìš©ë„**: search_document (ì¸ë±ì‹±ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ìƒì„± í•¨ìˆ˜\n",
    "def encode_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format='JPEG')\n",
    "        return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def generate_embedding(text, image_base64=None):\n",
    "    if image_base64:\n",
    "        payload = {\n",
    "            \"input_type\": \"search_document\",\n",
    "            \"embedding_types\": [\"float\"],\n",
    "            \"inputs\": [{\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": text},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "                ]\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"input_type\": \"search_document\",\n",
    "            \"embedding_types\": [\"float\"],\n",
    "            \"texts\": [text]\n",
    "        }\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId='cohere.embed-v4:0',\n",
    "        body=json.dumps(payload),\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['body'].read())\n",
    "    if isinstance(result['embeddings'], list):\n",
    "        return result['embeddings'][0][\"float\"]\n",
    "    else:\n",
    "        return result['embeddings']['float'][0]\n",
    "        \n",
    "\n",
    "print(\"ì„ë² ë”© í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 7. ì„ë² ë”© ìƒì„± ë° OpenSearch ì—…ë¡œë“œ\n",
    "\n",
    "ê° ì•„ì´í…œì— ëŒ€í•´ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  OpenSearchì— ì¸ë±ì‹±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì²˜ë¦¬ ê³¼ì •:\n",
    "1. **í…ìŠ¤íŠ¸ êµ¬ì„±**: ë©”íƒ€ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "2. **ì´ë¯¸ì§€ ì¸ì½”ë”©**: Base64ë¡œ ì´ë¯¸ì§€ ì¸ì½”ë”©\n",
    "3. **ì„ë² ë”© ìƒì„±**: Cohere Embed v4ë¡œ 1536ì°¨ì› ë²¡í„° ìƒì„±\n",
    "4. **ì¸ë±ì‹±**: OpenSearchì— ë¬¸ì„œ ì €ì¥\n",
    "\n",
    "âš ï¸ **ì°¸ê³ **: API ì œí•œì„ ê³ ë ¤í•˜ì—¬ ìš”ì²­ ê°„ 2ì´ˆ ëŒ€ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "import time\n# ì„ë² ë”© ìƒì„± ë° ì—…ë¡œë“œ\nprocessed_items = []\n\nfor item in sample_items:\n    print(f\"ì²˜ë¦¬ ì¤‘: {item['title']}\")\n    \n    # í…ìŠ¤íŠ¸ ìƒì„±\n    text = f\"Title: {item['title']}\\nDescription: {item['description']}\\nCategory: {item['category']}\\nBrand: {item['brand']}\\nColor: {item['color']}\\nPrice: ${item['price']}\"\n    \n    # ì´ë¯¸ì§€ ì¸ì½”ë”©\n    image_path = f\"data/images/{item['item_id']}.jpg\"\n    image_base64 = encode_image(image_path)\n    \n    # ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±\n    embedding = generate_embedding(text, image_base64)\n    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°\n    \n    # ë¬¸ì„œ ìƒì„±\n    doc = {\n        **item,\n        'multimodal_embedding': embedding,\n        'created_at': datetime.now().isoformat()\n    }\n    \n    # OpenSearchì— ì—…ë¡œë“œ (íƒ€ì„ì•„ì›ƒ 5ë¶„)\n    response = client.index(index=INDEX_NAME, body=doc, request_timeout=300)\n    processed_items.append(doc)\n    print(f\"ì™„ë£Œ: {item['item_id']} - {response['_id']}\")\n\nprint(f\"\\nëª¨ë“  ì•„ì´í…œ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_items)}ê°œ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ 7-2. ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ (Multi-Input Processing)\n",
    "\n",
    "ì—¬ëŸ¬ ì•„ì´í…œì„ í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“ ìš©ì–´ ì„¤ëª…:\n",
    "- **ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬**: Cohere APIì˜ `inputs` ë°°ì—´ì— ì—¬ëŸ¬ í•­ëª©ì„ í¬í•¨í•˜ì—¬ í•œ ë²ˆì— ì²˜ë¦¬\n",
    "- **Bedrock Batch Inference**: AWSê°€ ì œê³µí•˜ëŠ” S3 ê¸°ë°˜ ë¹„ë™ê¸° ë°°ì¹˜ API (ì„¹ì…˜ 7-3, Cohere Embed v4 ë¯¸ì§€ì›)\n",
    "\n",
    "### ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ ì¥ì :\n",
    "- **ë¹ ë¥¸ ì²˜ë¦¬**: API í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ (5ê°œ â†’ 1ê°œ)\n",
    "- **ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨**: ì˜¤ë²„í—¤ë“œ ê°ì†Œ\n",
    "- **ì¦‰ì‹œ ì‘ë‹µ**: ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "### ì²˜ë¦¬ ë°©ì‹:\n",
    "1. **ì…ë ¥ ê·¸ë£¹í™”**: ì—¬ëŸ¬ ì•„ì´í…œì„ í•˜ë‚˜ì˜ ìš”ì²­ìœ¼ë¡œ ë¬¶ìŒ\n",
    "2. **ì¼ê´„ ì„ë² ë”©**: í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ëª¨ë“  ì„ë² ë”© ìƒì„±\n",
    "3. **ë²Œí¬ ì¸ë±ì‹±**: OpenSearch bulk APIë¡œ ì¼ê´„ ì—…ë¡œë“œ\n",
    "\n",
    "âš ï¸ **ì°¸ê³ **: ì…ë ¥ ê·¸ë£¹ í¬ê¸°ëŠ” API ì œí•œ(6MB)ì„ ê³ ë ¤í•˜ì—¬ ì¡°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì¤‘ ì…ë ¥ ì„ë² ë”© ìƒì„± í•¨ìˆ˜\n",
    "def generate_batch_embeddings(items_data):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ì•„ì´í…œì˜ ì„ë² ë”©ì„ í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ìƒì„±\n",
    "    \n",
    "    ì´ í•¨ìˆ˜ëŠ” Cohere APIì˜ ë‹¤ì¤‘ ì…ë ¥ ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "    Bedrock Batch Inference APIì™€ëŠ” ë‹¤ë¥¸ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        items_data: [(text, image_base64), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ë‹¤ì¤‘ ì…ë ¥ í˜ì´ë¡œë“œ êµ¬ì„±\n",
    "    inputs = []\n",
    "    for text, image_base64 in items_data:\n",
    "        if image_base64:\n",
    "            inputs.append({\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": text},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "                ]\n",
    "            })\n",
    "        else:\n",
    "            inputs.append({\n",
    "                \"content\": [{\"type\": \"text\", \"text\": text}]\n",
    "            })\n",
    "    \n",
    "    payload = {\n",
    "        \"input_type\": \"search_document\",\n",
    "        \"embedding_types\": [\"float\"],\n",
    "        \"inputs\": inputs\n",
    "    }\n",
    "    \n",
    "    # API í˜¸ì¶œ\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId='cohere.embed-v4:0',\n",
    "        body=json.dumps(payload),\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['body'].read())\n",
    "    \n",
    "    # ì„ë² ë”© ì¶”ì¶œ\n",
    "    if isinstance(result['embeddings'], list):\n",
    "        return [emb[\"float\"] for emb in result['embeddings']]\n",
    "    else:\n",
    "        return result['embeddings']['float']\n",
    "\n",
    "print(\"âœ… ë‹¤ì¤‘ ì…ë ¥ ì„ë² ë”© í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ë¡œ ì„ë² ë”© ìƒì„± ë° ì—…ë¡œë“œ\nimport time\n\nbatch_processed_items = []\ngroup_size = 5  # í•œ ë²ˆì˜ API í˜¸ì¶œì— í¬í•¨í•  ì•„ì´í…œ ìˆ˜ (í•„ìš”ì‹œ ì¡°ì •)\n\nprint(f\"ğŸš€ ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ (ê·¸ë£¹ í¬ê¸°: {group_size})\\n\")\nstart_time = time.time()\n\n# ê·¸ë£¹ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\nfor i in range(0, len(sample_items), group_size):\n    group = sample_items[i:i+group_size]\n    group_num = i // group_size + 1\n    \n    print(f\"ğŸ“¦ ê·¸ë£¹ {group_num} ì²˜ë¦¬ ì¤‘ ({len(group)}ê°œ ì•„ì´í…œ)...\")\n    \n    # ì…ë ¥ ë°ì´í„° ì¤€ë¹„\n    batch_data = []\n    for item in group:\n        text = f\"Title: {item['title']}\\nDescription: {item['description']}\\nCategory: {item['category']}\\nBrand: {item['brand']}\\nColor: {item['color']}\\nPrice: ${item['price']}\"\n        image_path = f\"data/images/{item['item_id']}.jpg\"\n        image_base64 = encode_image(image_path)\n        batch_data.append((text, image_base64))\n    \n    # ë‹¤ì¤‘ ì…ë ¥ìœ¼ë¡œ ì„ë² ë”© ìƒì„± (1íšŒ API í˜¸ì¶œ)\n    embeddings = generate_batch_embeddings(batch_data)\n    \n    # OpenSearch bulk ì‘ì—… ì¤€ë¹„\n    bulk_body = []\n    for idx, (item, embedding) in enumerate(zip(group, embeddings)):\n        # ì¸ë±ìŠ¤ ì•¡ì…˜\n        bulk_body.append({\"index\": {\"_index\": INDEX_NAME}})\n        \n        # ë¬¸ì„œ ë°ì´í„°\n        doc = {\n            **item,\n            'multimodal_embedding': embedding,\n            'created_at': datetime.now().isoformat()\n        }\n        bulk_body.append(doc)\n        batch_processed_items.append(doc)\n    \n    # Bulk ì—…ë¡œë“œ (íƒ€ì„ì•„ì›ƒ 5ë¶„)\n    response = client.bulk(body=bulk_body, request_timeout=300)\n    \n    if response['errors']:\n        print(f\"   âš ï¸ ì¼ë¶€ ë¬¸ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨\")\n        for item in response['items']:\n            if 'error' in item['index']:\n                print(f\"      - ì˜¤ë¥˜: {item['index']['error']}\")\n    else:\n        print(f\"   âœ… ê·¸ë£¹ {group_num} ì™„ë£Œ ({len(group)}ê°œ ì•„ì´í…œ ì—…ë¡œë“œ)\")\n    \n    # API í˜¸ì¶œ ê°„ ì§§ì€ ëŒ€ê¸° (ì„ íƒì‚¬í•­)\n    if i + group_size < len(sample_items):\n        time.sleep(0.5)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"\\nâœ¨ ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ ì™„ë£Œ!\")\nprint(f\"ğŸ“Š ì²˜ë¦¬ëœ ì•„ì´í…œ: {len(batch_processed_items)}ê°œ\")\nprint(f\"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\nprint(f\"âš¡ í‰ê·  ì²˜ë¦¬ ì†ë„: {len(batch_processed_items)/elapsed_time:.2f}ê°œ/ì´ˆ\")\n\n# ê¸°ì¡´ ë°©ì‹ê³¼ ë¹„êµ\nsequential_time = len(sample_items) * 2  # 2ì´ˆì”© ëŒ€ê¸°\nprint(f\"\\nğŸ’¡ ì„±ëŠ¥ ë¹„êµ:\")\nprint(f\"   - ìˆœì°¨ ì²˜ë¦¬ (1ê°œì”©) ì˜ˆìƒ ì‹œê°„: ~{sequential_time}ì´ˆ\")\nprint(f\"   - ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ ({group_size}ê°œì”©) ì‹¤ì œ ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\nprint(f\"   - ì‹œê°„ ì ˆì•½: {sequential_time - elapsed_time:.2f}ì´ˆ ({(1 - elapsed_time/sequential_time)*100:.1f}% ë‹¨ì¶•)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 7-2-1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ìµœì í™” (ì˜µì…˜ 1: í° ê·¸ë£¹ í¬ê¸°)\n",
    "\n",
    "ë§Œ ê°œ ì´ìƒì˜ ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ í•œ ë²ˆì˜ API í˜¸ì¶œì— í¬í•¨í•  ì…ë ¥ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“ ì²˜ë¦¬ ë°©ì‹:\n",
    "- í•œ ë²ˆì˜ `invoke_model` í˜¸ì¶œì— ì—¬ëŸ¬ ì…ë ¥ì„ í¬í•¨\n",
    "- Bedrock Batch Inference APIì™€ëŠ” ë‹¤ë¥¸ ë°©ì‹\n",
    "\n",
    "### ì„±ëŠ¥ ì˜ˆì¸¡ (10,000ê°œ ê¸°ì¤€):\n",
    "- **ê·¸ë£¹ í¬ê¸° 20**: ~16ë¶„ (500íšŒ API í˜¸ì¶œ)\n",
    "- **ê·¸ë£¹ í¬ê¸° 50**: ~10ë¶„ (200íšŒ API í˜¸ì¶œ) â­ ê¶Œì¥\n",
    "- **ê·¸ë£¹ í¬ê¸° 100**: ~6-7ë¶„ (100íšŒ API í˜¸ì¶œ)\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- ê·¸ë£¹ í¬ê¸°ê°€ í´ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€\n",
    "- API ìš”ì²­ í¬ê¸° ì œí•œ(6MB) ê³ ë ¤\n",
    "- ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ê·¸ë£¹ í¬ê¸° ì¡°ì • í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„¤ì •\n",
    "LARGE_BATCH_SIZE = 50  # ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ìš© ë°°ì¹˜ í¬ê¸°\n",
    "\n",
    "# ì˜ˆì‹œ: ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë³µì œí•˜ì—¬ ëŒ€ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)\n",
    "# large_dataset = sample_items * 2000  # 10,000ê°œ ì‹œë®¬ë ˆì´ì…˜\n",
    "large_dataset = sample_items  # ì‹¤ì œ ì‚¬ìš© ì‹œ ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´\n",
    "\n",
    "print(f\"ğŸ“Š ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •\")\n",
    "print(f\"   - ë°ì´í„° ìˆ˜: {len(large_dataset)}ê°œ\")\n",
    "print(f\"   - ë°°ì¹˜ í¬ê¸°: {LARGE_BATCH_SIZE}ê°œ\")\n",
    "print(f\"   - ì˜ˆìƒ ë°°ì¹˜ ìˆ˜: {(len(large_dataset) + LARGE_BATCH_SIZE - 1) // LARGE_BATCH_SIZE}ê°œ\")\n",
    "print(f\"   - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~{((len(large_dataset) + LARGE_BATCH_SIZE - 1) // LARGE_BATCH_SIZE) * 3 / 60:.1f}ë¶„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ tqdm ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ tqdm ì„¤ì¹˜ ì¤‘...\")\n",
    "    !pip install tqdm -q\n",
    "    from tqdm import tqdm\n",
    "\n",
    "print(\"âœ… ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ì˜µì…˜ 1: í° ë°°ì¹˜ í¬ê¸°ë¡œ ì²˜ë¦¬ (ì§„í–‰ ìƒí™© í‘œì‹œ)\nimport time\nfrom tqdm import tqdm\n\nlarge_batch_items = []\nfailed_items = []\n\nprint(f\"ğŸš€ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {LARGE_BATCH_SIZE})\\n\")\nstart_time = time.time()\n\n# ì§„í–‰ ìƒí™© í‘œì‹œì™€ í•¨ê»˜ ë°°ì¹˜ ì²˜ë¦¬\ntotal_batches = (len(large_dataset) + LARGE_BATCH_SIZE - 1) // LARGE_BATCH_SIZE\n\nfor i in tqdm(range(0, len(large_dataset), LARGE_BATCH_SIZE), \n              total=total_batches,\n              desc=\"ë°°ì¹˜ ì²˜ë¦¬\",\n              unit=\"batch\"):\n    \n    batch = large_dataset[i:i+LARGE_BATCH_SIZE]\n    \n    try:\n        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„\n        batch_data = []\n        for item in batch:\n            text = f\"Title: {item['title']}\\nDescription: {item['description']}\\nCategory: {item['category']}\\nBrand: {item['brand']}\\nColor: {item['color']}\\nPrice: ${item['price']}\"\n            image_path = f\"data/images/{item['item_id']}.jpg\"\n            image_base64 = encode_image(image_path)\n            batch_data.append((text, image_base64))\n        \n        # ë°°ì¹˜ ì„ë² ë”© ìƒì„±\n        embeddings = generate_batch_embeddings(batch_data)\n        \n        # OpenSearch bulk ì‘ì—… ì¤€ë¹„\n        bulk_body = []\n        for item, embedding in zip(batch, embeddings):\n            bulk_body.append({\"index\": {\"_index\": INDEX_NAME}})\n            doc = {\n                **item,\n                'multimodal_embedding': embedding,\n                'created_at': datetime.now().isoformat()\n            }\n            bulk_body.append(doc)\n            large_batch_items.append(doc)\n        \n        # Bulk ì—…ë¡œë“œ (íƒ€ì„ì•„ì›ƒ 5ë¶„)\n        response = client.bulk(body=bulk_body, request_timeout=300)\n        \n        if response['errors']:\n            for item in response['items']:\n                if 'error' in item['index']:\n                    failed_items.append(item)\n    \n    except Exception as e:\n        tqdm.write(f\"âš ï¸ ë°°ì¹˜ {i//LARGE_BATCH_SIZE + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n        failed_items.extend(batch)\n        # ì—ëŸ¬ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ê³„ì†\n        time.sleep(2)\n    \n    # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°\n    if i + LARGE_BATCH_SIZE < len(large_dataset):\n        time.sleep(0.3)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"\\nâœ¨ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!\")\nprint(f\"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:\")\nprint(f\"   - ì„±ê³µ: {len(large_batch_items)}ê°œ\")\nprint(f\"   - ì‹¤íŒ¨: {len(failed_items)}ê°œ\")\nprint(f\"   - ì„±ê³µë¥ : {len(large_batch_items)/len(large_dataset)*100:.1f}%\")\nprint(f\"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)\")\nprint(f\"âš¡ í‰ê·  ì²˜ë¦¬ ì†ë„: {len(large_batch_items)/elapsed_time:.2f}ê°œ/ì´ˆ\")\n\nif failed_items:\n    print(f\"\\nâš ï¸ ì‹¤íŒ¨í•œ ì•„ì´í…œì´ ìˆìŠµë‹ˆë‹¤. ì¬ì‹œë„ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ 7-2-2. ë³‘ë ¬ ë‹¤ì¤‘ ì…ë ¥ ì²˜ë¦¬ (ì˜µì…˜ 2: ë©€í‹°ìŠ¤ë ˆë“œ)\n",
    "\n",
    "ì—¬ëŸ¬ API í˜¸ì¶œì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ì„ ë”ìš± ë‹¨ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“ ì²˜ë¦¬ ë°©ì‹:\n",
    "- ë©€í‹°ìŠ¤ë ˆë“œë¡œ ì—¬ëŸ¬ `invoke_model` í˜¸ì¶œì„ ë³‘ë ¬ ì‹¤í–‰\n",
    "- ê° í˜¸ì¶œì€ ì—¬ëŸ¬ ì…ë ¥ì„ í¬í•¨ (ë‹¤ì¤‘ ì…ë ¥)\n",
    "- Bedrock Batch Inference APIì™€ëŠ” ë‹¤ë¥¸ ë°©ì‹\n",
    "\n",
    "### ì„±ëŠ¥ ì˜ˆì¸¡ (10,000ê°œ ê¸°ì¤€):\n",
    "- **ë‹¨ì¼ ìŠ¤ë ˆë“œ**: ~10ë¶„ (200íšŒ API í˜¸ì¶œ)\n",
    "- **3ê°œ ë³‘ë ¬**: ~3-4ë¶„ (200íšŒ API í˜¸ì¶œì„ 3ê°œ ìŠ¤ë ˆë“œë¡œ ë¶„ì‚°) â­ ê¶Œì¥\n",
    "- **5ê°œ ë³‘ë ¬**: ~2-3ë¶„ (API ì œí•œ ì£¼ì˜)\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ API ì œí•œì— ê±¸ë¦´ ìœ„í—˜ ì¦ê°€\n",
    "- 3-5ê°œ ë³‘ë ¬ ì²˜ë¦¬ ê¶Œì¥\n",
    "- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport time\nfrom threading import Lock\n\n# ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì¹´ìš´í„°\nprogress_lock = Lock()\nprocessed_count = 0\n\ndef process_single_batch(batch, batch_id):\n    \"\"\"\n    ë‹¨ì¼ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n    \"\"\"\n    global processed_count\n    \n    try:\n        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„\n        batch_data = []\n        for item in batch:\n            text = f\"Title: {item['title']}\\nDescription: {item['description']}\\nCategory: {item['category']}\\nBrand: {item['brand']}\\nColor: {item['color']}\\nPrice: ${item['price']}\"\n            image_path = f\"data/images/{item['item_id']}.jpg\"\n            image_base64 = encode_image(image_path)\n            batch_data.append((text, image_base64))\n        \n        # ë°°ì¹˜ ì„ë² ë”© ìƒì„±\n        embeddings = generate_batch_embeddings(batch_data)\n        \n        # OpenSearch bulk ì‘ì—… ì¤€ë¹„\n        bulk_body = []\n        docs = []\n        for item, embedding in zip(batch, embeddings):\n            bulk_body.append({\"index\": {\"_index\": INDEX_NAME}})\n            doc = {\n                **item,\n                'multimodal_embedding': embedding,\n                'created_at': datetime.now().isoformat()\n            }\n            bulk_body.append(doc)\n            docs.append(doc)\n        \n        # Bulk ì—…ë¡œë“œ (íƒ€ì„ì•„ì›ƒ 5ë¶„)\n        response = client.bulk(body=bulk_body, request_timeout=300)\n        \n        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸\n        with progress_lock:\n            processed_count += len(batch)\n        \n        return {\n            'success': True,\n            'batch_id': batch_id,\n            'count': len(batch),\n            'docs': docs,\n            'errors': response.get('errors', False)\n        }\n    \n    except Exception as e:\n        return {\n            'success': False,\n            'batch_id': batch_id,\n            'count': len(batch),\n            'error': str(e)\n        }\n\nprint(\"âœ… ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜µì…˜ 2: ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬\n",
    "from tqdm import tqdm\n",
    "\n",
    "PARALLEL_BATCH_SIZE = 50\n",
    "MAX_WORKERS = 3  # ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜ (3-5 ê¶Œì¥)\n",
    "\n",
    "parallel_batch_items = []\n",
    "parallel_failed_items = []\n",
    "processed_count = 0\n",
    "\n",
    "print(f\"ğŸš€ ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘\")\n",
    "print(f\"   - ë°°ì¹˜ í¬ê¸°: {PARALLEL_BATCH_SIZE}ê°œ\")\n",
    "print(f\"   - ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜: {MAX_WORKERS}ê°œ\")\n",
    "print(f\"   - ë°ì´í„° ìˆ˜: {len(large_dataset)}ê°œ\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ë°°ì¹˜ ê·¸ë£¹ ìƒì„±\n",
    "batches = []\n",
    "for i in range(0, len(large_dataset), PARALLEL_BATCH_SIZE):\n",
    "    batch = large_dataset[i:i+PARALLEL_BATCH_SIZE]\n",
    "    batches.append((batch, i // PARALLEL_BATCH_SIZE))\n",
    "\n",
    "# ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    # ëª¨ë“  ë°°ì¹˜ ì‘ì—… ì œì¶œ\n",
    "    futures = {executor.submit(process_single_batch, batch, batch_id): batch_id \n",
    "               for batch, batch_id in batches}\n",
    "    \n",
    "    # ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "    with tqdm(total=len(batches), desc=\"ë³‘ë ¬ ì²˜ë¦¬\", unit=\"batch\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            \n",
    "            if result['success']:\n",
    "                parallel_batch_items.extend(result['docs'])\n",
    "                if result['errors']:\n",
    "                    tqdm.write(f\"âš ï¸ ë°°ì¹˜ {result['batch_id']}: ì¼ë¶€ ë¬¸ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            else:\n",
    "                tqdm.write(f\"âŒ ë°°ì¹˜ {result['batch_id']} ì‹¤íŒ¨: {result['error']}\")\n",
    "                parallel_failed_items.append(result)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'ì„±ê³µ': len(parallel_batch_items), 'ì‹¤íŒ¨': len(parallel_failed_items)})\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nâœ¨ ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"   - ì„±ê³µ: {len(parallel_batch_items)}ê°œ\")\n",
    "print(f\"   - ì‹¤íŒ¨: {len(parallel_failed_items)}ê°œ ë°°ì¹˜\")\n",
    "print(f\"   - ì„±ê³µë¥ : {len(parallel_batch_items)/len(large_dataset)*100:.1f}%\")\n",
    "print(f\"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)\")\n",
    "print(f\"âš¡ í‰ê·  ì²˜ë¦¬ ì†ë„: {len(parallel_batch_items)/elapsed_time:.2f}ê°œ/ì´ˆ\")\n",
    "\n",
    "# ë‹¨ì¼ ìŠ¤ë ˆë“œì™€ ë¹„êµ\n",
    "single_thread_time = (len(large_dataset) / PARALLEL_BATCH_SIZE) * 3\n",
    "speedup = single_thread_time / elapsed_time\n",
    "print(f\"\\nğŸ’¡ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(f\"   - ë‹¨ì¼ ìŠ¤ë ˆë“œ ì˜ˆìƒ: ~{single_thread_time/60:.1f}ë¶„\")\n",
    "print(f\"   - ë³‘ë ¬ ì²˜ë¦¬ ì‹¤ì œ: {elapsed_time/60:.1f}ë¶„\")\n",
    "print(f\"   - ì†ë„ í–¥ìƒ: {speedup:.1f}ë°°\")\n",
    "\n",
    "if parallel_failed_items:\n",
    "    print(f\"\\nâš ï¸ {len(parallel_failed_items)}ê°œ ë°°ì¹˜ ì‹¤íŒ¨. ì¬ì‹œë„ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìš”ì•½\n",
    "\n",
    "**10,000ê°œ ë°ì´í„° ì²˜ë¦¬ ì‹œê°„ ë¹„êµ:**\n",
    "\n",
    "| ë°©ì‹ | ì†Œìš” ì‹œê°„ | ì²˜ë¦¬ ì†ë„ | ë‚œì´ë„ |\n",
    "|------|----------|----------|--------|\n",
    "| ìˆœì°¨ ì²˜ë¦¬ (ì„¹ì…˜ 7) | ~5.5ì‹œê°„ | 0.5ê°œ/ì´ˆ | ì‰¬ì›€ |\n",
    "| ë™ê¸° ë°°ì¹˜ (ì„¹ì…˜ 7-2) | ~10ë¶„ | 16ê°œ/ì´ˆ | ì‰¬ì›€ |\n",
    "| í° ë°°ì¹˜ (ì„¹ì…˜ 7-2-1) | ~6-10ë¶„ | 16-27ê°œ/ì´ˆ | ì‰¬ì›€ |\n",
    "| ë³‘ë ¬ ë°°ì¹˜ (ì„¹ì…˜ 7-2-2) | ~3-4ë¶„ | 40-55ê°œ/ì´ˆ | ì¤‘ê°„ |\n",
    "\n",
    "**ê¶Œì¥ ì‚¬í•­:**\n",
    "- ğŸ“¦ **< 1,000ê°œ**: ì„¹ì…˜ 7-2 (ê¸°ë³¸ ë°°ì¹˜)\n",
    "- ğŸ“¦ **1,000-10,000ê°œ**: ì„¹ì…˜ 7-2-1 (í° ë°°ì¹˜)\n",
    "- âš¡ **> 10,000ê°œ**: ì„¹ì…˜ 7-2-2 (ë³‘ë ¬ ë°°ì¹˜)\n",
    "\n",
    "**ì£¼ì˜ì‚¬í•­:**\n",
    "- ë³‘ë ¬ ì²˜ë¦¬ ì‹œ API ì œí•œì— ì£¼ì˜\n",
    "- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§\n",
    "- ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ ê¶Œì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 8. ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œë¥¼ ì§€ì›í•˜ëŠ” í†µí•© ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê²€ìƒ‰ ëª¨ë“œ:\n",
    "- **í…ìŠ¤íŠ¸ ê²€ìƒ‰**: í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë§Œ ì‚¬ìš©\n",
    "- **ì´ë¯¸ì§€ ê²€ìƒ‰**: ì´ë¯¸ì§€ ì¿¼ë¦¬ë§Œ ì‚¬ìš©  \n",
    "- **ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰**: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ê²°í•© ì¿¼ë¦¬\n",
    "\n",
    "### ê²€ìƒ‰ ê³¼ì •:\n",
    "1. **ì¿¼ë¦¬ ì„ë² ë”©**: ì…ë ¥ì„ 1536ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n",
    "2. **k-NN ê²€ìƒ‰**: HNSW ì¸ë±ìŠ¤ì—ì„œ ìœ ì‚¬ ë²¡í„° íƒìƒ‰\n",
    "3. **ê²°ê³¼ ë°˜í™˜**: ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ìƒìœ„ kê°œ ê²°ê³¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def search(query_text=None, query_image_path=None, top_k=3):\n    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n    if query_image_path and query_text:\n        # ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)\n        image_base64 = encode_image(query_image_path)\n        payload = {\n            \"input_type\": \"search_query\",\n            \"embedding_types\": [\"float\"],\n            \"inputs\": [{\n                \"content\": [\n                    {\"type\": \"text\", \"text\": query_text},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n                ]\n            }]\n        }\n    elif query_image_path:\n        # ì´ë¯¸ì§€ ì „ìš© ê²€ìƒ‰\n        image_base64 = encode_image(query_image_path)\n        payload = {\n            \"input_type\": \"search_query\",\n            \"embedding_types\": [\"float\"],\n            \"inputs\": [{\n                \"content\": [\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n                ]\n            }]\n        }\n    else:\n        # í…ìŠ¤íŠ¸ ì „ìš© ê²€ìƒ‰\n        payload = {\n            \"input_type\": \"search_query\",\n            \"embedding_types\": [\"float\"],\n            \"texts\": [query_text]\n        }\n    \n    response = bedrock_client.invoke_model(\n        modelId='cohere.embed-v4:0',\n        body=json.dumps(payload),\n        contentType='application/json'\n    )\n    \n    result = json.loads(response['body'].read())\n    if isinstance(result['embeddings'], list):\n        query_embedding = result['embeddings'][0][\"float\"]\n    else:\n        query_embedding = result['embeddings']['float'][0]\n    \n    # ê²€ìƒ‰ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ 5ë¶„)\n    search_query = {\n        \"size\": top_k,\n        \"query\": {\n            \"knn\": {\n                \"multimodal_embedding\": {\n                    \"vector\": query_embedding,\n                    \"k\": top_k\n                }\n            }\n        },\n        \"_source\": {\"excludes\": [\"multimodal_embedding\"]}\n    }\n    \n    response = client.search(index=INDEX_NAME, body=search_query, request_timeout=300)\n    \n    results = []\n    for hit in response['hits']['hits']:\n        result = hit['_source']\n        result['score'] = hit['_score']\n        results.append(result)\n    \n    return results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results, query_desc):\n",
    "    print(f\"\\n=== ê²€ìƒ‰ ê²°ê³¼: {query_desc} ===\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“Š ì´ {len(results)}ê°œ ê²°ê³¼ ë°œê²¬\\n\")\n",
    "    \n",
    "    for i, item in enumerate(results, 1):\n",
    "        print(f\"{i}. {item['title']} (ì ìˆ˜: {item['score']:.4f})\")\n",
    "        print(f\"   {item['category']} | {item['brand']} | {item['color']} | ${item['price']}\")\n",
    "        print(f\"   {item['description']}\")\n",
    "        print()\n",
    "\n",
    "print(\"ğŸ” ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª 9. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "êµ¬í˜„ëœ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:\n",
    "1. **í…ìŠ¤íŠ¸ ê²€ìƒ‰**: \"ë¸”ë£¨ ìºì£¼ì–¼ ì¬í‚·\" í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "2. **ì´ë¯¸ì§€ ê²€ìƒ‰**: íŠ¹ì • ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ì•„ì´í…œ ê²€ìƒ‰\n",
    "3. **ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰**: í…ìŠ¤íŠ¸ ì„¤ëª… + ì´ë¯¸ì§€ ê²°í•© ê²€ìƒ‰\n",
    "\n",
    "ê° ê²€ìƒ‰ ê²°ê³¼ëŠ” ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
    "results = search(query_text=\"ë¸”ë£¨ ìºì£¼ì–¼ ì¬í‚· ì¼ìƒë³µ\")\n",
    "display_results(results, \"í…ìŠ¤íŠ¸ ê²€ìƒ‰: ë¸”ë£¨ ìºì£¼ì–¼ ì¬í‚·\")\n",
    "\n",
    "# 2. ì´ë¯¸ì§€ ê²€ìƒ‰\n",
    "results = search(query_image_path=\"data/images/item_001.jpg\")\n",
    "display_results(results, \"ì´ë¯¸ì§€ ê²€ìƒ‰: item_001.jpg\")\n",
    "\n",
    "# 3. ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰\n",
    "results = search(\n",
    "    query_text=\"ìš°ì•„í•œ ì •ì¥ íŠ¹ë³„í•œ í–‰ì‚¬ìš©\",\n",
    "    query_image_path=\"data/images/item_002.jpg\"\n",
    ")\n",
    "display_results(results, \"ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰: ìš°ì•„í•œ ì •ì¥ + ì´ë¯¸ì§€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ì¸ë±ìŠ¤ ì¡´ì¬ ë° ë¬¸ì„œ ìˆ˜ í™•ì¸\nprint(f\"ì¸ë±ìŠ¤ ì¡´ì¬: {client.indices.exists(index=INDEX_NAME, request_timeout=300)}\")\n\n# ë¬¸ì„œ ìˆ˜ í™•ì¸\nresponse = client.search(index=INDEX_NAME, body={\"query\": {\"match_all\": {}}, \"size\": 0}, request_timeout=300)\ndoc_count = response['hits']['total']['value']\nprint(f\"ë¬¸ì„œ ìˆ˜: {doc_count}\")\n\nif doc_count == 0:\n    print(\"âŒ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì„ë² ë”© ì—…ë¡œë“œê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n    print(\"API ì œí•œì´ í•´ì œëœ í›„ ì„ë² ë”© ìƒì„± ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 11. ì†”ë£¨ì…˜ ìš”ì•½\n",
    "\n",
    "êµ¬ì¶•ëœ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì£¼ìš” ì •ë³´ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ‰ êµ¬ì¶• ì™„ë£Œëœ ê¸°ëŠ¥:\n",
    "- âœ… **HNSW ë²¡í„° ì¸ë±ìŠ¤**: ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ê²€ìƒ‰\n",
    "- âœ… **ë©€í‹°ëª¨ë‹¬ ì„ë² ë”©**: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•©\n",
    "- âœ… **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: OpenSearch Serverless\n",
    "- âœ… **ìœ ì—°í•œ ê²€ìƒ‰**: 3ê°€ì§€ ê²€ìƒ‰ ëª¨ë“œ ì§€ì›\n",
    "\n",
    "### ğŸš€ ì„±ëŠ¥ íŠ¹ì§•:\n",
    "- **ê²€ìƒ‰ ì†ë„**: O(log N) HNSW ì•Œê³ ë¦¬ì¦˜\n",
    "- **ì„ë² ë”© í’ˆì§ˆ**: Cohere Embed v4 (1536ì°¨ì›)\n",
    "- **ìœ ì‚¬ë„ ì¸¡ì •**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "- **ìë™ ìŠ¤ì¼€ì¼ë§**: OpenSearch Serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ì†”ë£¨ì…˜ ì •ë³´ ===\")\nprint(f\"OpenSearch ì—”ë“œí¬ì¸íŠ¸: {ENDPOINT}\")\nprint(f\"ì¸ë±ìŠ¤: {INDEX_NAME}\")\nprint(f\"ì„ë² ë”© ëª¨ë¸: Cohere embed-v4\")\nprint(f\"ì„ë² ë”© ì°¨ì›: 1536\")\nprint(f\"ì²˜ë¦¬ëœ ì•„ì´í…œ: {len(processed_items)}ê°œ\")\nprint(\"\\n=== ì†”ë£¨ì…˜ êµ¬ì¶• ì™„ë£Œ ===\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}